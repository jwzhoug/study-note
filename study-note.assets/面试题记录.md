# 同步阻塞/ 非阻塞 .异步 非组赛

https://www.cnblogs.com/-900401/p/4015048.html

# 为什么要使用RPC

由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用。 在集群上面部署了引用之后，我们需要解决的问题就是怎么去调用，远程的机器上的应用，这时候就出现了RPC这样的远程调用协议。

# spirng IOC+DI 优缺点

ioc优点：

* 我们不再需要手动创建对象，管理依赖，spring ioc 以更灵活的方式管理对象

IoC最大的缺点是什么？

1. 生成一个对象的步骤变复杂了（事实上操作还是挺简单的），对于不习惯这种方式的人，会觉得有些别扭和不直观。
2. 对象生成因为是使用反射编程，在效率上有些损耗。但相对于IoC提高的维护性和灵活性来说，这点损耗是微不足道的，除非某对象的生成对效率要求特别高。

# 对并发的理解

我自己对并发的理解就是，需要解决并发的时候数据修改带来的数据不一致的问题，为什么会不一致呢？

比如转账，我们需要先从数据库获取他的原来的金额，然后加上转入的金额，然后修改数据库的数值，假设有一个账户余额是1000，这时候有两个人同时给他转账3000，这时候如果有两个请求同时执行，阀门发起了两个数据库事务，他们同时获取到了余额1000，然后+3000 = 4000，然后再去修改，这时候就算数据库使用了行锁或则表锁，同步这两个事务但是最后修改得到的结果后还是4000，而不是7000.

这就是并发会带来的问题，那么我们怎解决呢？

* 在同一个进程中，那么我们需要做线程之间的同步。

  比如使用锁，可以用juc下的锁比如`ReentrantLock`,或则使用`Synchronized`，或者下面同步进程的方式也是可以同步线程的。

* 在不同进程中，我们需要做进程之间的同步

  同样是使用锁的原理：比用使用redis实现分布式锁，使用zookeeper实现分布式锁，甚至使用数据库，只要能实现锁的同步效果，都可以使用



## 消息队列 推拉模型比较

**推模型（Push方式）**  由消息中间件主动的将消息推送给消费者； 

**拉模型（Pull方式）**  由消费者主动向中间件拉取消息； 

 两种模式各有优势，Push方式可以尽快的将消息发送给消费者；而Pull方式的好处在于可以进一步的解除消费者对于消息中间件的依赖，通过后台任务去定期的访问消息队列中的消息。  Push方式的坏处是，如果一个消费者处理消息的能力很弱，而消息中间件不停的向其发送消息，则会导致消费者缓冲溢出；  Pull方法需要引进一个单独的服务进程，加大消耗的资源。  

## 三个线程A,B,C，轮流输出ABC，顺序不可打乱，各十次。

* 第一种方式

  采用自旋等待

  ```java
  static void mothed1() {
          PrintA printA = new PrintA();
          PrintB printB = new PrintB();
          PrintC printC = new PrintC();
          // 输出A 要得到 C 的允许
          printA.setPrintMessage(printC);
          // 输出B 要得到 A 的允许
          printB.setPrintMessage(printA);
          // 输出C 要得到 B 的允许
          printC.setPrintMessage(printB);
          // 设置C 允许 A 输出
          printC.setFlag(true);
          printA.start();
          printB.start();
          printC.start();
      }
  
  /**
   * used template method 
   * 使用了模板方法模式
   */
  abstract class PrintMessage extends Thread {
      volatile boolean flag = false;
      PrintMessage printMessage;
  	  static int printNum = 10;
      abstract protected void printMessage();
  
      @Override
      public void run() {
          for (int i = 0; i < printNum; i++) {
              while (this.flag || !printMessage.flag) {
              }// 这个while 用来阻塞线程
              printMessage();
              printMessage.flag = false;//修改他前一个为没有输出
              this.flag = true;//这个表示它输出过一次了
          }
      }
  
      void setFlag(boolean flag) {
          this.flag = flag;
      }
  
      void setPrintMessage(PrintMessage printMessage) {
          this.printMessage = printMessage;
      }
  }
  /**
   * 输出A的线程
   */
  class PrintA extends PrintMessage {
      @Override
      protected void printMessage() {
          System.out.print("A");
      }
  }
  /**
   * 输出B的线程
   */
  class PrintB extends PrintMessage {
      protected void printMessage() {
          System.out.print("B");
      }
  }
  
  /**
   * 输出C的线程
   */
  class PrintC extends PrintMessage {
      @Override
      protected void printMessage() {
          System.out.print("C");
      }
  }
  ```

## 负载均衡算法设计

有一个消息队列集群，集群里每台Broker的响应时间RT都不一样，但是每台Broker的极限服务QPS都是一样的，超过这个QPS会出现过载雪崩。而消息的生产者客户端，每次发送都会选择其中的一台broker来发送，一般来说发送逻辑是运行在一个线程池里面。假设cpu资源充足，通过实现一个负载均衡算法，使得生产者能够达到最大吞吐量，最优的平均响应时间，但是又不能把任何一台服务器压垮。已知每个broker的rt、极限qps，消息生产者的线程数量，请求总数，如果采用吞吐量最优的算法，求处理完所有请求需要的耗时，单位毫秒。

概念说明：

QPS：query per second， 每秒请求量

RT：response time，请求的响应时间

Broker：消息队列的服务器

import java.util.Scanner;

public class Main {

​    public static void main(String[] args)  {

​        Scanner in = new Scanner(System.in);

​        int maxQps= Integer.valueOf(in.nextLine());

​        final String[] rtList = in.nextLine().split(",");

​        final int requestNum = Integer.valueOf(in.nextLine());

​        final int threadNum = Integer.valueOf(in.nextLine());

​        System.out.println(doneTime(maxQps, rtList, requestNum, threadNum));

​    }

​    /**

​     * 如果使用最优的最大吞吐量负载均衡算法，按照最优模型多久能够处理完所有请求，单位毫秒。

​     * @return

​     */

​    static long doneTime(int maxQps,String[] rtList,int requestNum,int threadNum) {

​        //TODO

​                

​        return 0;

​    }

}

#### 负载均衡算法

##### 前提

cpu资源充足

##### 前提

* 最大QPS = 最大并发量/响应时间 如果单位是毫秒也就是说QPS 是单位毫秒处理请求的最大数量
* 这个题我们知道了多台服务器的 最大QPS maxQPS 以及响应时间 RT
* 这样我们能可以计算出一台服务器的 最大并发量 maxConcurrentNum
* 多线程推送请求

有了maxConcurrentNum 这个作为权重（这里我们排除加权轮询法）

我们需要根据这个权重maxConcurrentNum 来选择最后请求落在哪一个服务器

##### 基础逻辑设计

先选择权重最大的，然后将请求给他，同时他的权重-1，服务器处理完了之后权重+1，这样应该落在什么地方就根据权重排序来找了。

##### 解决多进程问题数据共享问题

在分布式中（多进程），这时候需要借助中间件来管理，推荐redis（高可用（性能杠杠的））

##### 解决并发问题

* 单进程中

  当前要保证这个权重值在并发的时候的修改时原子的，可以使用原子类来实现

* 多进程（分布式项目）中

  使用分布式锁同步多个进程

##### 分布式中的服务发现

服务器ip 需要借助中间件来实现服务发现，这里推荐的服务发现管理的中间件是zookeeper或则redis

zookeeper 的主从特性避免了单点问题保证了系统的 可靠性

redis也有相同的功能 

由于我们要管理这个权重然后redis 同时可以做服务发现和这个权重管理的高可用所以最后选中使用redis

当然也可以用zookeeper 做服务发现，redis管理权重

##### 最后是需要计算处理所有请求的时间的

最大QPS = 最大并发量/响应时间 如果单位是毫秒也就是说QPS 是单位毫秒处理请求的最大数量

也就是说我们需要知道处理玩这些所有请求后，每一台服务器 处理的请求的数量 reqNum

reqNum/maxQps = 这台服务器消耗的时间（单位毫秒）spendTime

然后找出服务器中spendTime 中最大的 maxSpendTime 就是处理这些请求的最大时间



##  zookeeper 在分布式中是作为一个服务协调的角色

比如作为注册中心，配置中心，实现分布式锁，集群管理，分布式消息队列

实际上，这些功能的实现都是依赖于背后 zookeeper与 client 之间的 Lease 

## dubbo 在分布式中是作为一个服务治理的角色

服务注册发现，熔断，限流.......

### Paxos 协议

​	从前面的例子不难看出，Paxos 协议的过程类似于“占坑”，哪个 value 把超过半数的“坑”
（Acceptor）占住了，哪个 value 就得到批准了。 

​	这个过程也类似于单机系统并行系统的加锁过程。假如有这么单机系统：系统内有 5 个锁，有
多个线程执行，每个线程需要获得 5 个锁中的任意 3 个才能执行后续操作，操作完成后释放占用的
锁。我们知道，上述单机系统中一定会发生“死锁”。例如，3 个线程并发，第一个线程获得 2 个锁，
第二个线程获得 2 个锁，第三个线程获得 1 个锁。此时任何一个线程都无法获得 3 个锁，也不会主
动释放自己占用的锁，从而造成系统死锁。 

​	但在 Paxos 协议过程中，虽然也存在着并发竞争，不会出现上述死锁。这是因为，Paxos 协议
引入了轮数的概念，高轮数的 paxos 提案可以抢占低轮数的 paxos 提案。从而避免了死锁的发生。
然而这种设计却引入了“活锁”的可能，即 Proposer 相互不断以更高的轮数提出议案，使得每轮 Paxos
过程都无法最终完成，从而无法批准任何一个 value。 





